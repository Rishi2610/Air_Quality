{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trial_csv_export.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP55uikSRxR5jnU9jx47SiH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishi2610/Air_Quality/blob/main/trial_csv_export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv3UhsBrKaNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56fd5eb-497d-4c43-9d86-f69c4bdcd0b2"
      },
      "source": [
        "#Mount drive to save files there\n",
        "#clone the repository to access files from there\n",
        "#pull the latest\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "! git clone https://github.com/Rishi2610/Air_Quality.git\n",
        "! git -C Air_Quality/ pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'Air_Quality'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTxkRB897HJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9203d013-704a-46be-acfb-a44063ee4c6e"
      },
      "source": [
        "! pip install netCDF4\n",
        "from netCDF4 import Dataset\n",
        "import numpy as np\n",
        "import sys\n",
        "import time\n",
        "import calendar\n",
        "import datetime as dt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting netCDF4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/71/a321abeee439caf94850b4f68ecef68d2ad584a5a9566816c051654cff94/netCDF4-1.5.5.1-cp36-cp36m-manylinux2014_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 4.6MB/s \n",
            "\u001b[?25hCollecting cftime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/60/bad8525d2c046eb2964911bc412a85ba240b31c7b43f0c19377233992c6c/cftime-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (295kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from netCDF4) (1.19.4)\n",
            "Installing collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.3.0 netCDF4-1.5.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpy4FnpQvFtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b9270a-4756-4f93-9156-00ddb70ea2b5"
      },
      "source": [
        "\n",
        "#!/usr/bin/python      \n",
        "\n",
        "#This finds the user's current path so that all hdf4 files can be found\n",
        "try:\n",
        "    fileList = open('Air_Quality/filelist.txt', 'r')\n",
        "\n",
        "except:\n",
        "    print('Did not find a text file containing file names (perhaps name does not match)')\n",
        "    sys.exit()\n",
        "\n",
        "#loops through all files listed in the text file\n",
        "for FILE_NAME in fileList:\n",
        "    FILE_NAME=FILE_NAME.strip()\n",
        "    user_input=input('\\nWould you like to process\\n' + FILE_NAME + '\\n\\n(Y/N)')\n",
        "    if (user_input == 'N' or user_input == 'n'):\n",
        "        print('Skipping...')\n",
        "        continue\n",
        "    else:\n",
        "        file = Dataset('Air_Quality/' + FILE_NAME, 'r')\n",
        "# read the data\n",
        "        if 'AERDB' in FILE_NAME:\n",
        "            print('This is a VIIRS Deep Blue file.')\n",
        "            #this is how you access the data tree in an hdf5 file\n",
        "            SDS_NAME='Aerosol_Optical_Thickness_550_Land_Best_Estimate'    \n",
        "        ds=file  \n",
        "        lat= ds.variables['Latitude'][:][:]\n",
        "        lon= ds.variables['Longitude'][:][:]\n",
        "        data= ds.variables[SDS_NAME]\n",
        "\n",
        "        #get necessary attributes \n",
        "        fv=data._FillValue\n",
        "          \n",
        "        fileparts=FILE_NAME.split('.')\n",
        "\n",
        "        #There are some columns that are going to be the same\n",
        "        #like the year, month and so on listed below.\n",
        "        #Therefore, we can make the columns for them to store\n",
        "        #the data for every row.\n",
        "        year = np.zeros(lat.shape)\n",
        "        mth = np.zeros(lat.shape)\n",
        "        doy = np.zeros(lat.shape)\n",
        "        hr = np.zeros(lat.shape)\n",
        "        mn = np.zeros(lat.shape)\n",
        "        \n",
        "        for i in range(0,lat.shape[0]):\n",
        "            y= fileparts[1][1:5]\n",
        "            h = fileparts[2][0:2]\n",
        "            m = fileparts[2][2:4]\n",
        "            date = y + ',' + fileparts[1][5:8] + ',' + h + ',' + m\n",
        "            t2 = dt.datetime.strptime(date,'%Y,%j,%H,%M')\n",
        "           \n",
        "            mt = t2.month\n",
        "            d = t2.day\n",
        "            \n",
        "            year[i][:] = y\n",
        "            mth[i][:] = mt\n",
        "            doy[i][:] = d\n",
        "            hr[i][:] = h\n",
        "            mn[i][:] = m\n",
        "            \n",
        "        vlist = list(file.variables.keys())\n",
        "        \n",
        "        #create the dataframe and enter the values here\n",
        "        df = pd.DataFrame()\n",
        "        df['Year'] = year.ravel()\n",
        "        df['Month'] = mth.ravel()\n",
        "        df['Day'] = doy.ravel()\n",
        "        df['Hour'] = hr.ravel()\n",
        "        df['Minute'] = mn.ravel()\n",
        "        \n",
        "        #0-->Aerosol_Optical_Thickness_550_Land\n",
        "        #3-->Aerosol_Optical_Thickness_550_Land_Ocean_Best_Estimate\n",
        "        #8-->Aerosol_Optical_Thickness_QA_Flag_Land\n",
        "        #11-->Aerosol_Type_Land_Ocean\n",
        "        #18-->Angstrom_Exponent_Land_Ocean_Best_Estimate\n",
        "        sds_lst = [ 'Aerosol_Optical_Thickness_550_Land',\n",
        "                   'Aerosol_Optical_Thickness_550_Land_Ocean_Best_Estimate',\n",
        "                   'Aerosol_Optical_Thickness_QA_Flag_Land',\n",
        "                   'Aerosol_Type_Land_Ocean',\n",
        "                   'Angstrom_Exponent_Land_Ocean_Best_Estimate']\n",
        "        \n",
        "        #This for loop saves all of the SDS in the dictionary at the top (dependent on file type) to the array (with titles)\n",
        "        #All the sds that we need seem to be contained in this range.\n",
        "        #Can extend this range to loop through more sds variables in the NC file.\n",
        "        for i in range(0,20):\n",
        "            SDS_NAME=vlist[(i)] # The name of the sds to read\n",
        "            \n",
        "            if SDS_NAME in sds_lst:\n",
        "                print('SDS_NAME', SDS_NAME)\n",
        "                #try:\n",
        "                sds=ds.variables[SDS_NAME]\n",
        "               \n",
        "                scale = 1.0\n",
        "                fv=sds._FillValue\n",
        "                #get SDS data as a vector\n",
        "                data=sds[:].ravel()\n",
        "               #The next few lines change fill value/missing value to NaN so that we can multiply valid values by the scale factor, then back to fill values for saving\n",
        "                data=data.astype(float)\n",
        "                data=(data)*scale  \n",
        "                data[np.isnan(data)]=fv\n",
        "                data[data==float(fv)]=np.nan\n",
        "                data=np.array(data[:])\n",
        "                df[SDS_NAME] = data\n",
        "    \n",
        "    outfilename=FILE_NAME[:-3]+'.csv'    \n",
        "    df.to_csv(\"drive/My Drive/Colab Notebooks/\" + outfilename, index = False) \n",
        "    print('\\nAll files have been saved successfully.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Would you like to process\n",
            "AERDB_L2_VIIRS_SNPP.A2020280.0624.001.2020280191843.nc\n",
            "\n",
            "(Y/N)Y\n",
            "This is a VIIRS Deep Blue file.\n",
            "SDS_NAME Aerosol_Optical_Thickness_550_Land\n",
            "SDS_NAME Aerosol_Optical_Thickness_550_Land_Ocean_Best_Estimate\n",
            "SDS_NAME Aerosol_Optical_Thickness_QA_Flag_Land\n",
            "SDS_NAME Aerosol_Type_Land_Ocean\n",
            "SDS_NAME Angstrom_Exponent_Land_Ocean_Best_Estimate\n",
            "\n",
            "All files have been saved successfully.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}